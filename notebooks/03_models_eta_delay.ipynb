{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NYC Delivery Promise Engine: ETA Prediction & Delay Classification Models\n",
        "\n",
        "## Notebook Overview\n",
        "This notebook trains machine learning models for delivery promise optimization:\n",
        "1. **ETA Regression Model**: Predicts trip duration for median (P50) estimates\n",
        "2. **Delay Classification Model**: Predicts probability of exceeding P90 threshold\n",
        "3. **Model Evaluation**: Performance metrics and feature importance analysis\n",
        "\n",
        "### Business Context\n",
        "- **ETA Model**: Provides realistic delivery time estimates\n",
        "- **Delay Model**: Identifies high-risk deliveries for dynamic promise adjustments\n",
        "- **Combined**: Enables P50 vs P90 promise strategy optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import mean_absolute_error, roc_auc_score, precision_recall_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"ü§ñ NYC Delivery Promise Engine - Model Training\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load processed data from feature engineering\n",
        "print(\"Loading processed datasets...\")\n",
        "try:\n",
        "    df_train = pd.read_csv('../data/processed_train_data.csv')\n",
        "    df_test = pd.read_csv('../data/processed_test_data.csv')\n",
        "    print(f\"‚úÖ Training data: {len(df_train):,} records\")\n",
        "    print(f\"‚úÖ Test data: {len(df_test):,} records\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Processed data not found. Please run 02_feature_engineering.ipynb first.\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Feature Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature preparation for machine learning\n",
        "print(\"\\nüîß Feature Preparation\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Select features for modeling\n",
        "numeric_features = ['trip_distance', 'pickup_hour', 'pickup_dow']\n",
        "categorical_features = ['pickup_borough', 'dropoff_borough']\n",
        "\n",
        "# Encode categorical features\n",
        "le_dict = {}\n",
        "for feature in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    # Fit on combined data to ensure consistent encoding\n",
        "    combined_values = pd.concat([df_train[feature], df_test[feature]]).unique()\n",
        "    le.fit(combined_values)\n",
        "    \n",
        "    df_train[f'{feature}_encoded'] = le.transform(df_train[feature])\n",
        "    df_test[f'{feature}_encoded'] = le.transform(df_test[feature])\n",
        "    le_dict[feature] = le\n",
        "    \n",
        "    print(f\"‚úÖ Encoded {feature}: {len(le.classes_)} categories\")\n",
        "\n",
        "# Define feature columns for modeling\n",
        "feature_cols = numeric_features + [f'{f}_encoded' for f in categorical_features]\n",
        "target_col = 'trip_duration_minutes'\n",
        "\n",
        "print(f\"\\nüìä Model Features: {feature_cols}\")\n",
        "print(f\"üéØ Target: {target_col}\")\n",
        "\n",
        "# Prepare training and test sets\n",
        "X_train = df_train[feature_cols].copy()\n",
        "y_train = df_train[target_col].copy()\n",
        "X_test = df_test[feature_cols].copy() \n",
        "y_test = df_test[target_col].copy()\n",
        "\n",
        "print(f\"\\n‚úÖ Feature matrices prepared:\")\n",
        "print(f\"Training: {X_train.shape}, Test: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ETA Regression Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ETA regression model\n",
        "print(\"\\nüìà Training ETA Regression Model\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Initialize Random Forest regressor\n",
        "rf_regressor = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=15,\n",
        "    min_samples_split=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Training model...\")\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "print(\"‚úÖ ETA model training completed!\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"\\nüìä ETA Model Performance:\")\n",
        "print(f\"Mean Absolute Error: {mae:.2f} minutes\")\n",
        "\n",
        "# Calculate P90 coverage (important for delivery promises)\n",
        "residuals = y_test - y_pred\n",
        "p90_adjustment = np.percentile(residuals, 90)\n",
        "y_pred_p90 = y_pred + p90_adjustment\n",
        "p90_coverage = (y_test <= y_pred_p90).mean()\n",
        "\n",
        "print(f\"P90 Coverage: {p90_coverage:.1%} (target: ~90%)\")\n",
        "\n",
        "# Model statistics\n",
        "print(f\"\\nüìà Prediction Quality:\")\n",
        "print(f\"Actual - Mean: {y_test.mean():.1f}, Median: {y_test.median():.1f}\")\n",
        "print(f\"Predicted - Mean: {y_pred.mean():.1f}, Median: {np.median(y_pred):.1f}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': rf_regressor.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(f\"\\nüîç Top 5 Feature Importance:\")\n",
        "for _, row in feature_importance.head().iterrows():\n",
        "    print(f\"{row['feature']:20s}: {row['importance']:.3f}\")\n",
        "\n",
        "# Save model\n",
        "print(f\"\\nüíæ Saving ETA model...\")\n",
        "joblib.dump(rf_regressor, '../artifacts/models/eta_model.pkl')\n",
        "joblib.dump(le_dict, '../artifacts/models/label_encoders.pkl')\n",
        "print(\"‚úÖ Model saved to artifacts/models/\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
